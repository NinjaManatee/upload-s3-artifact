# Mirrors action/upload-artifact, taking many of the same parameters, but uploads to S3 instead of GitHub.
name: Upload artifact(s) to AWS S3
description: Uploads artifact(s) to an AWS S3 bucket

# Inputs, outputs and descriptions pulled from actions/upload-artifact
inputs:
  name:
    description: Artifact name
    default: artifact
  path:
    description: A file, directory or wildcard pattern that describes what to upload
    required: true
  if-no-files-found:
    type: choice
    description: >
      The desired behavior if no files are found using the provided path.

      Available Options:
        warn: Output a warning but do not fail the action
        error: Fail the action with an error message
        ignore: Do not output any warnings or errors, the action does not fail
    options:
      - warn
      - error
      - ignore
    default: warn
  retention-days:
    description: >
      Duration after which returned URL will expire in days. 0 means using default retention. This is only for the 
      presigned URL returned by the action and printed to the job summary. Controlling when an artifact is actually 
      deleted is done in the AWS S3 bucket configuration.

      Minimum 1 day.
      Maximum 90 days unless changed from the repository settings page.
      default is 7 days
    type: number
    default: 7
  compression-level:
    type: choice
    description: >
      The level of compression for Zlib to be applied to the artifact archive.
      The value can range from 0 to 9:
        - 0: No compression
        - 1: Best speed
        - 6: Default compression (same as GNU Gzip)
        - 9: Best compression
      Higher levels will result in better compression, but will take longer to complete.
      For large files that are not easily compressed, a value of 0 is recommended for significantly faster uploads.
    options:
      - 0
      - 1
      - 2
      - 3
      - 4
      - 5
      - 6
      - 7
      - 8
      - 9
    default: 6
  # TODO: Implement overwrite
  overwrite:
    description: >
      If true, an artifact with a matching name will be deleted before a new one is uploaded.
      If false, the action will fail if an artifact for the given name already exists.
      Does not fail if the artifact does not exist.
    default: false
    type: boolean
  include-hidden-files:
    description: >
      If true, hidden files will be included in the artifact.
      If false, hidden files will be excluded from the artifact.
    default: false
    type: boolean

outputs:
  artifact-url:
    description: >
      A download URL for the artifact that was just uploaded. Empty if the artifact upload failed.

      This download URL only works for requests Authenticated with GitHub. Anonymous downloads will be prompted to first login. 
      If an anonymous download URL is needed than a short time restricted URL can be generated using the download artifact API: https://docs.github.com/en/rest/actions/artifacts#download-an-artifact    

      This URL will be valid for as long as the artifact exists and the workflow run and repository exists. Once an artifact has expired this URL will no longer work.
      Common uses cases for such a download URL can be adding download links to artifacts in descriptions or comments on pull requests or issues.
  artifact-digest:
    description: >
      SHA-256 digest for the artifact that was just uploaded. Empty if the artifact upload failed.

env:
  S3_ARTIFACTS_BUCKET: ${{ env.S3_ARTIFACTS_BUCKET }}
  AWS_ACCESS_KEY_ID: ${{ env.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ env.AWS_SECRET_ACCESS_KEY }}

runs:
  using: 'composite'
  steps:
    - name: Upload artifact
      shell: bash
      run: |
        # read inputs into variables
        export INPUT_NAME="${{ inputs.name }}"
        export INPUT_PATH="${{ inputs.path }}"
        export INPUT_IF_NO_FILES_FOUND="${{ inputs.if-no-files-found }}"
        export INPUT_RETENTION_DAYS="${{ inputs.retention-days }}"
        export INPUT_COMPRESSION_LEVEL="${{ inputs.compression-level }}"
        export INPUT_OVERWRITE="${{ inputs.overwrite }}"
        export INPUT_INCLUDE_HIDDEN_FILES="${{ inputs.include-hidden-files }}"

        # read github actions variables
        export RUNNER_OS="${{ runner.os }}"
        export GITHUB_REPOSITORY="${{ github.repository }}"
        export GITHUB_RUN_ID="${{ github.run_id }}"

        # read environment variables
        # TODO: Are these necessary since they are already environment variables?
        export ENV_S3_ARTIFACTS_BUCKET="${{ env.S3_ARTIFACTS_BUCKET }}"
        export ENV_AWS_ACCESS_KEY_ID="${{ env.AWS_ACCESS_KEY_ID }}"
        export ENV_AWS_SECRET_ACCESS_KEY="${{ env.AWS_SECRET_ACCESS_KEY }}"

        # print inputs for debugging
        echo "::debug::Inputs:"
        echo "::debug::    name:                      $INPUT_NAME"
        echo "::debug::    path:                      $INPUT_PATH"
        echo "::debug::    if-no-files-found:         $INPUT_IF_NO_FILES_FOUND"
        echo "::debug::    retention-days:            $INPUT_RETENTION_DAYS"
        echo "::debug::    compression-level:         $INPUT_COMPRESSION_LEVEL"
        echo "::debug::    overwrite:                 $INPUT_OVERWRITE"
        echo "::debug::    include-hidden-files:      $INPUT_INCLUDE_HIDDEN_FILES"
        echo "::debug::    runner.os:                 $RUNNER_OS"
        echo "::debug::    github.repository:         $GITHUB_REPOSITORY"
        echo "::debug::    github.run-id:             $GITHUB_RUN_ID"
        echo "::debug::    S3_ARTIFACTS_BUCKET:       $ENV_S3_ARTIFACTS_BUCKET"
        echo "::debug::    AWS_ACCESS_KEY_ID:         $ENV_AWS_ACCESS_KEY_ID"
        echo "::debug::    AWS_SECRET_ACCESS_KEY:     $ENV_AWS_SECRET_ACCESS_KEY"

        ACTION_PATH=$GITHUB_ACTION_PATH
        if [[ "${{ runner.os }}" == "Windows" ]]; then
          # Need to make sure path in ACTION_PATH is a unix path
          ACTION_PATH=$(cygpath -u "$ACTION_PATH")
        fi

        # run script
        $ACTION_PATH/scripts/main.sh